version: '2.2'

services:
  scalellm:
    image: vectorchai/scalellm:latest
    hostname: scalellm
    container_name: scalellm
    network_mode: "host"
    volumes:
      - /home/michael/code/codellama:/models
    command: --model_path=/models/CodeLlama-7b-Python --logtostderr
    # turn on GPU access
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  scalellm-gateway:
    image: vectorchai/scalellm-gateway:latest
    hostname: scalellm-gateway
    container_name: scalellm-gateway
    network_mode: "host"
    command: --grpc-server=localhost:8888 --logtostderr
    depends_on:
      - scalellm

  chatbot-ui:
    image: vectorchai/chatbot-ui:latest
    hostname: chatbot-ui
    container_name: chatbot-ui
    network_mode: "host"
    environment:
      - OPENAI_API_HOST=http://127.0.0.1:8080
      - OPENAI_API_KEY=YOUR_API_KEY
      - DEFAULT_SYSTEM_PROMPT=You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.
    depends_on:
      - scalellm-gateway
      - scalellm
